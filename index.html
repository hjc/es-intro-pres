<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>A Light Introduction to Elasticsearch</title>

		<meta name="description" content="A quick presentation teaching you about ES.">
		<meta name="author" content="Hayden Chudy">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/solarized.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Elasticsearch</h1>
					<h3>A Short Introduction</h3>
					<p>
						<small>Created by <a href="http://haydenchudy.com">Hayden Chudy</a> / <a href="http://twitter.com/hjc1710">@hjc1710</a></small>
					</p>
				</section>

				<section>
					<h2>What is Elasticsearch?</h2>
					<ul>
						<li>
							A distributed, clusterable search server powered by a JSON DSL for searching.
						</li>
						<li>
							Really, just a layer of abstractions on top Lucene to store more structured data.
						</li>
						<li>
							Can also be used as a simple document-oriented NoSQL database.
							<ul>
								<li>Sort of like Mongo with better queries and even <b>less</b> relations.</li>
								<li>Normally backed by another database storage engine though.</li>
							</ul>
						</li>
						<li>Written in Java.</li>
					</ul>

					<aside class="notes">
						<ul>
							<li>
								Layer of abstractions - Lucene only stores strings, but ES supports storing, indexing
								and searching through complicated JSON structures, this is all done through clever use
								of key names and values within Lucene, that ES turns into a structure of sort
							</li>
							<li>
								Some people use ES as their primary storage engine, especially if their core data source
								is logs. However, ES is frequently joined with another database storage engine, and data
								is mirrored between the two.
							</li>
						</ul>
					</aside>
				</section>

				<!-- Example of nested vertical slides -->
				<section>
					<h2>What is Lucene?</h2>
					<ul>
						<li>Open Source project by Apache to write an Information Retrieval (IR) System.</li>
						<li>IR Systems use metadata and full text search to make finding information very efficient.</li>
						<li>Provides a robust and accurate scoring algorithm.</li>
						<li>A number of major search engine solutions are built on top of Lucene.</li>
						<li>Started in 1999 by Doug Cutting, adopted by Apache in 2001, became it's own top level project in 2005.</li>
						<li>Also written in Java, providing a robust native Java API.</li>
					</ul>

					<aside class="notes">
						<ul>
							<li>
								IR Systems are focused on efficiently searching for and retrieving information, as
								opposed to being focused on efficiently storing said information (which is what normal
								DBMS's are focused on).
							</li>
							<li>
								For example: a common strategy in IR to improve search robustness is to index the
								same field of data in multiple, different fashions so it can match more complex
								queries. Compare this to relational DB, where you are constantly trying to lower how
								many duplicate entries of a field there are.
							</li>
							<li>
								The scoring algorithm used is: tf-idf. However, individual query objects can affect
								tf-idf scoring and lie at the heart of why Lucene scoring is great.
							</li>
							<li>
								Large projects built on top of Lucene, in addition to ES, include:
								<ul>
									<li>Solr</li>
									<li>Compass (precursor to ES)</li>
									<li>
										Swiftype (an enterprise search start up that sells search solutions to other sites,
										built on top of Lucene)
									</li>
									<li>KinoSearch (another big search server like Solr)</li>
								</ul>
							</li>
							<li>
								Some people even use Lucene directly and circumvent the likes of Solr and ES entirely.
								Examples of this include: Apple.com, LinkedIn, Jira, and, formerly, Twitter.
							</li>
							<li>ES utilizes Lucene's Java API to provide fast, native access.</li>
						</ul>
					</aside>
				</section>

				<section>
					<h2>Let's Begin!</h2>
				</section>

				<section>
					<h2>Installing Elasticsearch</h2>
					<ul>
						<li>Use the Vagrantfile in this repository.</li>
						<li>Use your Operating System's package manager:</li>
					</ul>
					<pre><code data-trim>
# latest on Ubuntu
$ apt-get install openjdk-7-jdk
$ wget -qO-  http://packages.elasticsearch.org/GPG-KEY-elasticsearch - | apt-key add -
$ echo "deb http://packages.elasticsearch.org/elasticsearch/1.7/debian stable main" > /etc/apt/sources.list.d/elasticsearch.list
$ apt-get update
$ apt-get install elasticsearch
# OSX with Brew
$ brew install elasticsearch
					</code></pre>
					<aside class="notes">
						<ul>
							<li>Vagrant requires version 1.6+, vagrant-bindfs, and vagrant-salt.</li>
							<li>Install those and vagrant up, and vagrant will forward port 9200 for you.</li>
						</ul>
					</aside>
				</section>

				<section>
					<h2>Seeing if it Works</h2>
					<pre><code data-trim>
hayden@beardtop ~> curl -XGET localhost:9200
{
	"status" : 200,
	"name" : "Madam Slay",
	"cluster_name" : "elasticsearch",
	"version" : {
		"number" : "1.7.1",
		"build_hash" : "b88f43fc40b0bcd7f173a1f9ee2e97816de80b19",
		"build_timestamp" : "2015-07-29T09:54:16Z",
		"build_snapshot" : false,
		"lucene_version" : "4.10.4"
	},
	"tagline" : "You Know, for Search"
}
					</code></pre>
					<aside class="notes">
						<ul>
							<li>
								Seeing if ES is up and running is simple: just curl port 9200 and see if you get
								a response!
							</li>
							<li>Fun fact, all Elasticsearch node names come from Marvel super hero names.</li>
						</ul>
					</aside>
				</section>

				<section>
					<h2>Indexing Your First Item</h2>
					<pre><code data-trim>
hayden@beardtop ~> curl -XPOST "localhost:9200/croscon/employees/1" -d '{
	"name": "Tom Sawyer",
	"id": 1,
	"specialties": ["javascript", "php"]
}'
{"_index":"croscon","_type":"employees","_id":"1","_version":1,"created":true}

hayden@beardtop ~> curl -XGET "localhost:9200/croscon/employees/1"
{"_index":"croscon","_type":"employees","_id":"1","_version":1,"found":true,"_source":{
	"name": "Tom Sawyer",
	"id": 1,
	"specialties": ["javascript", "php"]
}}
					</code></pre>

					<aside class="notes">
						<ul>
							<li>Indexing is as simple as a POST request.</li>
							<li>
								We explicitly specified the id in the path, but you can also omit it and let ES
								create one on its own.
							</li>
							<li>Fetching is then as simple as GETing the route by id.</li>
							<li>
								The URL scheme goes as follows: $ES_URL/$INDEX_NAME/$TYPE_NAME/$DOCUMENT_ID.
								<ul>
									<li>
										An index is a collection of documents that have somewhat similar characteristics.
										For example, you can have an index for customer data, and another index for a
										product catalog. An index is identified by a name (that must be all lowercase) and
									</li>
									<li>
										A type is a logical category/partition of your index whose structure is up to you.
										In general, a type is defined for documents that have a set of common fields.
										For example, letâ€™s assume you run a blogging platform and store all your data
										in a single index. In this index, you may define a type for user data,
										another type for blog data, and yet another type for comments data.
									</li>
									<li>
										A document is a basic unit of information that can be indexed.
										For example, you can have a document for a single customer, another document
										for a single product, and yet another for a single order.
										This document is expressed in JSON, much like Mongo.
										<br/>
										Within an index/type, you can store as many documents as you want. Note
										that although a document physically resides in an index, a document actually
										must be indexed/assigned to a type inside an index.
									</li>
								</ul>
							</li>
						</ul>
					</aside>
				</section>

				<section>
					<h2>Updating Data</h2>
					<pre><code data-trim>
hayden@beardtop ~> curl -XPUT "localhost:9200/croscon/employees/1" -d '{
	"name": "Tom Sawyer",
	"id": 1,
	"specialties": ["javascript", "php"],
	"date_of_birth": "1990-12-10"
}'
{"_index":"croscon","_type":"employees","_id":"1","_version":2,"created":false}

hayden@beardtop ~> curl -XGET "localhost:9200/croscon/employees/1"
{"_index":"croscon","_type":"employees","_id":"1","_version":2,"found":true,"_source":{
	"name": "Tom Sawyer",
	"id": 1,
	"specialties": ["javascript", "php"],
	"date_of_birth": "1990-12-10"
}}
					</code></pre>
					<aside class="notes">
						Let's add a new date of birth field.
						<br/>
						To update an item, you merely PUT to the route by ID with the new, complete
						document. Deleting of fields is done by omission.
						<br/>
						Brand new fields are automatically mapped into the index, parsed, and saved.
						<br/>
						Known fields are parsed as described by their mappings, and saved.
						<br/>
						<br/>
						Some more employee data:
						{ "name": "Ben Rogers", "id": 2, "specialties": ["css", "less", "magic"], "date_of_birth": "1987-08-10" }
						{ "name": "Huck Finn", "id": 3, "specialties": ["php", "python", "devops"], "date_of_birth": "1990-10-17" }
						{ "name": "Pap Finn", "id": 4, "specialties": ["php", "python", "devops", "magic"], "date_of_birth": "1984-07-16" }
					</aside>
				</section>

				<section>
					<section>
						<h2>Searching</h2>

						<h3>Getting Everyone</h3>
						<pre><code data-trim>
hayden@beardtop ~> curl -XGET 'localhost:9200/croscon/employees/_search'
{
  "took" : 3,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "hits" : {
    "total" : 4,
    "max_score" : 1.0,
    "hits" : [ {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "4",
      "_score" : 1.0,
      "_source":{ "name": "Pap Finn", "id": 4, "specialties": ["php", "python", "devops", "magic"], "date_of_birth": "1984-07-16" }
    }, {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "1",
      "_score" : 1.0,
      "_source":{"name": "Tom Sawyer","id": 1,"specialties": ["javascript", "php"],"date_of_birth": "1990-12-10"}
    }, {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "2",
      "_score" : 1.0,
      "_source":{ "name": "Ben Rogers", "id": 2, "specialties": ["css", "less", "magic"], "date_of_birth": "1987-08-10" }
    }, {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "3",
      "_score" : 1.0,
      "_source":{ "name": "Huck Finn", "id": 3, "specialties": ["php", "python", "devops"], "date_of_birth": "1990-10-17" }
    } ]
  }
}
						</code></pre>

						<aside class="notes">
							The presence of that `_search` is integral. Running a search against just an index
							and a type will produce an error along the lines of: `No endpoint found for
							$TYPENAME`.
							<br/>
							If you'll notice, these aren't in any real order, and every document returned
							has a score of: 1.0.
							<br/>
							When searching, `?pretty` is your friend, otherwise, all your results are returned
							minified.
						</aside>
					</section>
					<section>
						<h2>Searching</h2>

						<h3>Getting just the PHP'rs</h3>

						<pre><code data-trim>
hayden@beardtop ~> curl -XGET 'localhost:9200/croscon/employees/_search' -d '
{
  "query": {
    "term": {
      "specialties": "php"
    }
  }
}'

{
  "took" : 6,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "hits" : {
    "total" : 3,
    "max_score" : 0.19178301,
    "hits" : [ {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "1",
      "_score" : 0.19178301,
      "_source":{ "name": "Tom Sawyer","id": 1,"specialties": ["javascript", "php"],"date_of_birth": "1990-12-10" }
    }, {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "4",
      "_score" : 0.15342641,
      "_source":{ "name": "Pap Finn", "id": 4, "specialties": ["php", "python", "devops", "magic"], "date_of_birth": "1984-07-16" }
    }, {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "3",
      "_score" : 0.15342641,
      "_source":{ "name": "Huck Finn", "id": 3, "specialties": ["php", "python", "devops"], "date_of_birth": "1990-10-17" }
    } ]
  }
}

						</code></pre>
						<aside class="notes">
							And everyone but Paul is returned, as expected.
							<br/>
							If you'll notice, we searched for a string in an array rather easily, and ES will naturally
							make all of its queries just <i>work</i> with arrays.
							<br/>
							If you notice, the score has changed, but is still identical because TF-IDF is identical
							for both of us in this simple query.
						</aside>
					</section>
					<section>
						<h2>Searching</h2>
						<h3>Getting everyone born in 1990 and on:</h3>
						<pre><code data-trim>
hayden@beardtop ~> curl -XGET 'localhost:9200/croscon/employees/_search' -d '
{
  "query": {
    "range": {
      "date_of_birth": {
        "gte": "1990-01-01",
        "lte": "now"
      }
    }
  }
}'
{
  "hits" : {
    "total" : 2,
    "max_score" : 1.0,
    "hits" : [ {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "1",
      "_score" : 1.0,
      "_source":{ "name": "Tom Sawyer", "id": 1, "specialties": ["javascript", "php"],"date_of_birth": "1990-12-10" }
    }, {
      "_index" : "croscon",
      "_type" : "employees",
      "_id" : "3",
      "_score" : 1.0,
      "_source":{ "name": "Huck Finn", "id": 3, "specialties": ["php", "python", "devops"], "date_of_birth": "1990-10-17" }
    } ]
  }
}

						</code></pre>
						<aside class="notes">
							The `lte` for now is optional, but it is included to show you that ES has some strings
							with special meaning. This one turns into the current DateTime.
							<br/>
							You'll notice there's still no score here. That's because scoring a range query is
							<b>hard</b> and elasticsearch doesn't do <b>everything</b>
							<br/>
							These are all just very light examples, and all of the options given can be further
							customized to support boosting, multiple date formats, timeszones, etc.
							<br/>
							Segue into mapping with a note about: "But, wait... how did that date range search work?
							We just gave it a string? There were no explicit dates involved!"
						</aside>
					</section>
				</section>

				<section>
					<h2>Welcome to Mappings</h2>
					<pre><code data-trim>
hayden@beardtop ~> curl -XGET 'localhost:9200/_mapping?pretty'
{
  "croscon" : {
    "mappings" : {
      "employees" : {
        "properties" : {
          "date_of_birth" : {
            "type" : "date",
            "format" : "dateOptionalTime"
          },
          "id" : {
            "type" : "long"
          },
          "name" : {
            "type" : "string"
          },
          "specialties" : {
            "type" : "string"
          }
        }
      }
    }
  }
}
					</code></pre>
					<aside class="notes">
						<ul>
							<li>
								Behind the scenes, ES creates a mapping for each type it has in an index.
								It parses each JSON payload and makes an intelligent best guess at what
								type each field should be.
								<br/>
								If you'll notice, it guessed correctly that our date_of_birth field was a
								Date with an optional Time part, even though it was sent as a string.
								<br/>
								Mapping also works on nested objects and arrays, natively.
							</li>
							<li>
								Mapping is what make the magic ES queries possible, and also efficient.
							</li>
							<li>
								Some supported types: string, number, date, boolean, binary (base64 representation
								of binary data; not stored or indexed by default), arrays, objects, arrays of objects,
								ip addresses (IPv4 only), geographic points, and geographic shapes.
							</li>
							<li>
								The type of a field determines which queries can be run on it and how given queries
								are processed/run. For example, doing a range over numbers is done very differently
								then a range over IP's.
							</li>
						</ul>
					</aside>
				</section>

				<section>
					<section>
						<h2>Explicit Mappings</h2>
						<ul>
							<li>
								Either a file in <code>/etc/elasticsearch/templates</code> or dynamically PUT via an
								API request.
							</li>
							<li>
								Example:
							</li>
						</ul>
						<aside class="notes">
							While ES does determine automatic mappings for each type, you can also explicitly define
							a mapping for each type yourself, in case of ambiguous fields, complicated fields (such as
							multi-fields), or missing fields.
						</aside>
					</section>
					<section>
						<pre><code data-trim>
hayden@beardtop ~> curl -XPUT 'localhost:9200/croscon/_mapping/projects' -d '
{
  "projects": {
    "_id": {
      "index": "not_analyzed",
      "path": "id",
      "type": "long"
    },
    "properties": {
      "name": {
        "type": "string",
        "store": true,
        "index": "analyzed",
        "fields": {
          "raw": {
            "type": "string",
            "index": "not_analyzed"
          }
        }
      },
      "due_date": {
        "type": "date"
      },
      "id": {
        "type": "long"
      },
      "client": {
        "type": "object",
        "properties": {
          "id": {
            "type": "long"
          },
          "name": {
            "type": "string"
          }
        }
      }
    }
  }
}'
						</code></pre>
						<aside class="notes">
							<ul>
								<li>
									Multi-fields: Multi-fields are when you pass a given field through multiple
									analyzers and store multiple variations of it, for different searching reasons.
									A very common multi-field, is the `raw` field, which is just a string that is
									indexed as is, and is not parsed before being indexed.
								</li>
								<li>
									Stored vs. indexed.
									<br/>
									For any given field, you can choose to store and/or index it.
									<br/>
									Storing a field means it is stored directly alongside the document identifier.
									Think of it this way: Lucene just stores pointers to ID's, these ID's are then
									looked up in ES, and come with extra information. By default, the indexed JSON document
									is stored in the _source field and it can be parsed and used to return any field
									you desire. Alternatively, you can disable _source, to save space, or store
									an additional field explicitly, allowing you to fetch it without parsing _source.
									<br/>
									Indexing a field means it is inserted into Lucene and prepared for searching. To
									search over a field it <b>must</b> be indexed. You can index a field as analyzed
									or not_analyzed. Analyzed means it will be transformed before being inserted (more
									on that later), not analyzed means it is inserted into Lucene raw.
									<br/>
									By default, fields are indexed and not stored.
								</li>
							</ul>
						</aside>
					</section>
					<section>
						<h2>Breaking Your Mappings</h2>

						If you ever try to insert data that doesn't match your mappings, ES will slap you back
						with this:

						<pre><code data-trim>
hayden@beardtop ~> curl -XPOST 'localhost:9200/croscon/employees' -d '
{
  "name": "Ben Rogers",
  "id": 2,
  "specialties": ["css", "less", "magic"],
  "date_of_birth": "1987-XX-YY"
}'
{"error":"MapperParsingException[failed to parse [date_of_birth]];
nested: MapperParsingException[failed to parse date field
[1987-XX-YY], tried both date format [dateOptionalTime], and
timestamp number with locale []]; nested:
IllegalArgumentException[Invalid format: \"1987-XX-YY\" is
malformed at \"-XX-YY\"]; ","status":400}
						</code></pre>

						<aside class="notes">
							I will point out though, that this is a very useful error message.
						</aside>
					</section>
				</section>

				<section>
					<h2>TO THE MOON WITH SCORING AND ORDERING!</h2>

					<img src="img/doge-moon.png" alt="TO THE MOON!!!!!!!!!"/>
				</section>

				<section>
					<section>
						<h2>Ordering</h2>
						<pre><code data-trim>
hayden@beardtop ~> curl -XGET 'localhost:9200/croscon/employees/_search' -d '
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "due_date": {
        "order": "asc",
        "missing": "_last"
      }
    },
    {
      "name.raw": {
        "order": "desc"
      }
    },
    "_score"
  ]
}'
{
  "hits" : {
    "total" : 3,
    "max_score" : null,
    "hits" : [ {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "1",
      "_score" : 1.0,
      "_source":{"name": "MC3 Rearch", "due_date": "2015-09-08", "id": 1, "client": { "name": "HFA", "id": 1 } },
      "sort" : [ 1441670400000, "MC3 Rearch", 1.0 ]
    }, {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "2",
      "_score" : 1.0,
      "_source":{"name": "MC4", "due_date": "2016-12-21", "id": 2, "client": { "name": "Croscon", "id": 2 } },
      "sort" : [ 1482278400000, "MC4", 1.0 ]
    }, {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "3",
      "_score" : 1.0,
      "_source":{"name": "ZVM", "due_date": null, "id": 3, "client": null },
      "sort" : [ 9223372036854775807, "ZVM", 1.0 ]
    } ]
  }
}

						</code></pre>

						<aside class="notes">
							<ul>
								<li>
									Earlier, we lightly discussed that Lucene implemented multiple scoring algorithms.
									Internally, Elasticsearch uses these derived scores to determine the sort order for
									all results.
								</li>
								<li>
									However, we can override that sort order rather easy. We can sort on our arbitrary
									fields in whatever order we want, then we can let Elasticsearch's native score
									ordering kick in whenever.
								</li>
								<li>
									The order syntax is rather simple, but extendable:
									<ul>
										<li>
											Pick a field name, and then a direction.
										</li>
										<li>
											Alternatively, pick a field name, then open an object for more options! In
											the second example we're doing two things:
											<ol>
												<li>
													We're using our name.raw multi-field. We're using this because names
													are composed of two parts, a first and a last, and we want to sort on
													both of those names. If we were to run this over just the `name` field,
													we would get unpredictable results, due to how analyzers
													work (something we'll cover later).
												</li>
												<li>
													We're using the special `missing` option. `missing` tells ES what to do
													when it finds a document without this field. Rather, it tells ES what
													VALUE to give that document for this field. In this case, we're telling
													ES to give that document whatever value it needs to be sorted last
													(likely a name of: ""). If we wanted all missing names to be sorted as
													if they were equal to: "CROSCON", that would be as simple as changing
													"_last" to be "CROSCON" (an example of that would be nice).
												</li>
											</ol>
										</li>
										<li>
											Our final example is the score sorting fallback. If you just pass `_score`,
											then ES knows to sort on the score in a descending fashion! AWESOME!
										</li>
									</ul>
								</li>
							</ul>
						</aside>
					</section>
					<section>
						<h2>Ordering</h2>
						<pre><code data-trim>
 curl -XGET 'localhost:9200/croscon/projects/_search?pretty' -d '
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "due_date": {
        "order": "asc",
        "missing": "_first"
      }
    },
    {
      "name.raw": {
        "order": "desc"
      }
    },
    "_score"
  ]
}'
{
  "hits" : {
    "total" : 3,
    "max_score" : null,
    "hits" : [ {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "3",
      "_score" : 1.0,
      "_source":{"name": "ZVM", "due_date": null, "id": 3, "client": null },
      "sort" : [ -9223372036854775808, "ZVM", 1.0 ]
    }, {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "1",
      "_score" : 1.0,
      "_source":{"name": "MC3 Rearch", "due_date": "2015-09-08", "id": 1, "client": { "name": "HFA", "id": 1 } },
      "sort" : [ 1441670400000, "MC3 Rearch", 1.0 ]
    }, {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "2",
      "_score" : 1.0,
      "_source":{"name": "MC4", "due_date": "2016-12-21", "id": 2, "client": { "name": "Croscon", "id": 2 } },
      "sort" : [ 1482278400000, "MC4", 1.0 ]
    } ]
  }
}

						</code></pre>
						<aside class="notes">
							We can also make missing fields come first.s
						</aside>
					</section>

					<section>
						<h2>Ordering</h2>
						<pre><code data-trim>
curl -XGET 'localhost:9200/croscon/projects/_search?pretty' -d '
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "due_date": {
        "order": "asc",
        "missing": 1444455518000
      }
    },
    {
      "name.raw": {
        "order": "desc"
      }
    },
    "_score"
  ]
}'
{
  "hits" : {
    "total" : 3,
    "max_score" : null,
    "hits" : [ {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "1",
      "_score" : 1.0,
      "_source":{"name": "MC3 Rearch", "due_date": "2015-09-08", "id": 1, "client": { "name": "HFA", "id": 1 } },
      "sort" : [ 1441670400000, "MC3 Rearch", 1.0 ]
    }, {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "3",
      "_score" : 1.0,
      "_source":{"name": "ZVM", "due_date": null, "id": 3, "client": null },
      "sort" : [ 1444455518000, "ZVM", 1.0 ]
    }, {
      "_index" : "croscon",
      "_type" : "projects",
      "_id" : "2",
      "_score" : 1.0,
      "_source":{"name": "MC4", "due_date": "2016-12-21", "id": 2, "client": { "name": "Croscon", "id": 2 } },
      "sort" : [ 1482278400000, "MC4", 1.0 ]
    } ]
  }
}
						</code></pre>
						<aside class="notes">
							Or we can give it a specific value. In this example, we've given it the UNIX timestamp
							that corresponds to: 2015-10-10, putting it right in the middle
						</aside>
					</section>
				</section>

				<section>
					<h2>Scoring</h2>

					Show an actual search result and highlight the score, also introduce ?explain

					<aside class="notes">
						<ul>
							<li>
								The other part of ordering results is scoring. Scoring can basically be summed up as
								"Lucene gives a document a relevance score, indicating how relevant said document
								was to our initial search".
							</li>
							<li>
								Obviously, this is a wonderful thing to sort on.
							</li>
							<li>
								But, how the fuck does it work!?
							</li>
						</ul>
					</aside>
				</section>

				<section>
					<section>
						<h2>A Smidge of TF-IDF</h2>
						<ul>
							<li>
								TF-IDF is the algorithm that is the primary driving force behind Lucene's relevance score.
							</li>
							<li>
								TF-IDF = "Term Frequency - Inverse Document Frequency"
							</li>
							<li>
								Basically: the more a word appears in a single document, the more valuable it is; however
								the more it appears in MULTIPLE documents all in a single index, the LESS valuable it is.
							</li>
							<li>
								This sort of naturally handles things like Stop Words (and, the, is), but there are even
								better solutions to that problem later!
							</li>
						</ul>
					</section>

					<section>
						<img src="img/tfidf.png" alt="Image of TF IDF Formula" style="height: 600px;"/>

						<aside class="notes">
							Mathematically, the way this all works all plays out kind of like:
							<ol>
								<li>
									Calculate the term frequency. This can be done multiple ways, but the easiest
									way is to make it so term frequency == the raw frequency of a term in a document.
									Basically, if f(t, d) is the raw number of times a single term appears in a document,
									then tf(t, d) = f(t, d). Other, more complicated schemes apply, such as logarithmically
									scaled term frequencies [tf(t, d) = 1 + log(f(t, d))], or even augmented frequencies
									which prevent bias towards longer documents
									[tf(f, d) = 0.5 + ((0.5 x f(t, d)) / max(all_docs, key=f(t, d)))
								</li>
								<li>
									Calculate the inverse document frequency. The inverse document frequency is gotten
									by taking the log of the number of total documents in a corpus (or index, or collection
									of indices) divided by the total number of documents that contain this term, so:
									log(N / abs(sum(N, key=lambda x: term in x.terms)))
								</li>
								<li>
									Multiply those two.
								</li>
							</ol>
							In a nutshell: Maths. Mucho, mucho maths.
							<br/>
							Lucene does this for every query, and it does it an efficient manner!
						</aside>
					</section>

					<aside class="notes">

					</aside>
				</section>

				<section>
					<section>
						<h2>Analyzers, Tokenizers, and Filters</h2>

						<ul>
							<li>
								Analyzers, Tokenizers, Filters allow you to transform your textual data into a more
								searchable format.
							</li>
							<li>
								An Analyzer merely consists of a series of Tokenizers and Filters.
							</li>
							<li>
								Some example Tokenizers include: stop words, whitespace, etc.
							</li>
							<li>
								Example Filters include: stop words (again)... not sure what else.
							</li>
							<li>
								Customizing Analyzers, Filters, and Tokenizers is quite possible, but is FAR beyond
								the scope of this talk.
							</li>
							<li>
								An example analyzer would be: INSERT EXAMPLE HERE.
							</li>
						</ul>

						<aside class="notes">
							<ul>
								<li>
									Tokenizers split a single string into multiple, smaller constituent pieces,
									each of which is indexed and can be searched for.
								</li>
								<li>
									Tokenizers are the crux of search. Without tokenizers, you would have to search for
									an exact string to get any match out of ES. With tokenizers, ES will break each word
									in a string up into its own item, allowing you to search for just that.
								</li>
								<li>
									Tokenizers can also support things like multi-lingual search, if made robust enough.
								</li>
								<li>
									Filters get rid of all the noise in a search that we just don't need. The best example
									is a stop word. In the English language, a stop word is just a word that is used as
									a tool and really provides no semantic meaning to a sentence, such as and, or, or but.
									If we were to index this, it would become almost immediately useless due to how TF-IDF
									works, meaning it just takes up space. Well, instead of storing it... how about we
									strip it!? That's exactly what filters are for!
								</li>
								<li>
									When we're creating that `name.raw` field, all we're telling ES to do is... DON'T
									analyze that field at all, so we have the full string in tact and can work with it.
								</li>
							</ul>
						</aside>
					</section>

					<section>
						<h2>Stemming</h2>
						Stemming is taking a word and reducing it to its "root stem".
						For example, consider the word: skiing. The root of skiing is really just ski, and almost all
						searches for ski or skiing should return both. Another example is "dogs", whose root is dog. A
						search for dogs or dog should almost always be stemmed down because rarely do people care how
						many adorable puppies are in their returned search results.
					</section>

					<section>
						Analyzers and Tokenizers

						Might move this to be an explain section.
					</section>

					Remember how I said we had to search on name.raw, otherwise we'd get odd results? Well, this is where
					I explain why!
				</section>

				<section>
					<section>
						<h2>Making Search Work for You</h2>

						<ul>
							<li>
								So far, ES has been quite powerful, but it's not perfect. There are some things ES
								doesn't handle <b>at all</b>, such as array ordering.
							</li>
							<li>
								There are always workarounds though!
							</li>
							<li>
								The solution to your problems in ES are almost always: STORE MORE DATA!
							</li>
						</ul>

						<aside class="notes">
							Internally, it would be an ENORMOUS pain in the ass for ES to store information on the
							ordering of each array entry, so it just <i>doesn't</i> (why? Because ES stores arrays as:
							{"user_alias": "bob"}, {"user_alias": "tim"}, {"user_alias": "joe"}, with just the array
							key, because this is easy to search over, storing information about the ordering of the array
							in the key would, by definition, make every key for every array entry different, no es bueno).
						</aside>
					</section>
					<section>
						<h2>Making Search Work for You</h2>
						<ul>
							<li>
								Let's fix our problem of searching over the first item in an array.
							</li>
							<li>
								We'll do this by simply indexing the first item in that array:
								<pre><code data-trim>
doc = create_doc(id)
doc.top_specialty = specialities[0]
index_doc(doc)
								</code></pre>
							</li>
							<li>
								We can now search for everyone who's top specialty is <code>php</code> with:
								<pre><code data-trim>
hayden@beardtop ~> curl -XGET localhost:9200/croscon/employees/_search -d '
{
  "query": {
	"term": {
	  "top_specialty": "php"
	}
  }
}'

								</code></pre>
							</li>
							<li>
								We've now made our search more robust and powerful!
							</li>
							<li>
								Need to see if a document has exact contents of an array? Alpha sort it, join them
								all with commas, and index that! Rebuild this at search time and... PROFIT!!!!
							</li>
							<li>
								If scoring doesn't work for you, make your <b>data</b> work for you.
							</li>
						</ul>

						<aside class="notes">
							No really, that's what an ES core contributor told me to do when I had this problem!
						</aside>
					</section>
				</section>

				<section>
					<h2>Background Transitions</h2>
					<p>
						You can override background transitions per-slide.
					</p>
					<pre><code style="word-wrap: break-word;">&lt;section data-background-transition="zoom"&gt;</code></pre>
				</section>

				<section>
					<h2>Pretty Code</h2>
					<pre><code data-trim contenteditable>
function linkify( selector ) {
  if( supports3DTransforms ) {

    var nodes = document.querySelectorAll( selector );

    for( var i = 0, len = nodes.length; i &lt; len; i++ ) {
      var node = nodes[i];

      if( !node.className ) {
        node.className += ' roll';
      }
    }
  }
}
					</code></pre>
					<p>Code syntax highlighting courtesy of <a href="http://softwaremaniacs.org/soft/highlight/en/description/">highlight.js</a>.</p>
				</section>

				<section>
					<h2>Marvelous List</h2>
					<ul>
						<li>No order here</li>
						<li>Or here</li>
						<li>Or here</li>
						<li>Or here</li>
					</ul>
				</section>

				<section>
					<h2>Fantastic Ordered List</h2>
					<ol>
						<li>One is smaller than...</li>
						<li>Two is smaller than...</li>
						<li>Three!</li>
					</ol>
				</section>

				<section>
					<h2>Tabular Tables</h2>
					<table>
						<thead>
							<tr>
								<th>Item</th>
								<th>Value</th>
								<th>Quantity</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Apples</td>
								<td>$1</td>
								<td>7</td>
							</tr>
							<tr>
								<td>Lemonade</td>
								<td>$2</td>
								<td>18</td>
							</tr>
							<tr>
								<td>Bread</td>
								<td>$3</td>
								<td>2</td>
							</tr>
						</tbody>
					</table>
				</section>

				<section>
					<h2>Clever Quotes</h2>
					<p>
						These guys come in two forms, inline: <q cite="http://searchservervirtualization.techtarget.com/definition/Our-Favorite-Technology-Quotations">
						&ldquo;The nice thing about standards is that there are so many to choose from&rdquo;</q> and block:
					</p>
					<blockquote cite="http://searchservervirtualization.techtarget.com/definition/Our-Favorite-Technology-Quotations">
						&ldquo;For years there has been a theory that millions of monkeys typing at random on millions of typewriters would
						reproduce the entire works of Shakespeare. The Internet has proven this theory to be untrue.&rdquo;
					</blockquote>
				</section>

				<section>
					<h2>Intergalactic Interconnections</h2>
					<p>
						You can link between slides internally,
						<a href="#/2/3">like this</a>.
					</p>
				</section>

				<section>
					<h2>Speaker View</h2>
					<p>There's a <a href="https://github.com/hakimel/reveal.js#speaker-notes">speaker view</a>. It includes a timer, preview of the upcoming slide as well as your speaker notes.</p>
					<p>Press the <em>S</em> key to try it out.</p>

					<aside class="notes">
						Oh hey, these are some notes. They'll be hidden in your presentation, but you can see them if you open the speaker notes window (hit 's' on your keyboard).
					</aside>
				</section>

				<section>
					<h2>Export to PDF</h2>
					<p>Presentations can be <a href="https://github.com/hakimel/reveal.js#pdf-export">exported to PDF</a>, here's an example:</p>
					<iframe src="//www.slideshare.net/slideshow/embed_code/42840540" width="445" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:3px solid #666; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>
				</section>

				<section>
					<h2>Global State</h2>
					<p>
						Set <code>data-state="something"</code> on a slide and <code>"something"</code>
						will be added as a class to the document element when the slide is open. This lets you
						apply broader style changes, like switching the page background.
					</p>
				</section>

				<section data-state="customevent">
					<h2>State Events</h2>
					<p>
						Additionally custom events can be triggered on a per slide basis by binding to the <code>data-state</code> name.
					</p>
					<pre><code class="javascript" data-trim contenteditable style="font-size: 18px;">
Reveal.addEventListener( 'customevent', function() {
	console.log( '"customevent" has fired' );
} );
					</code></pre>
				</section>

				<section>
					<h2>Take a Moment</h2>
					<p>
						Press B or . on your keyboard to pause the presentation. This is helpful when you're on stage and want to take distracting slides off the screen.
					</p>
				</section>

				<section>
					<h2>Much more</h2>
					<ul>
						<li>Right-to-left support</li>
						<li><a href="https://github.com/hakimel/reveal.js#api">Extensive JavaScript API</a></li>
						<li><a href="https://github.com/hakimel/reveal.js#auto-sliding">Auto-progression</a></li>
						<li><a href="https://github.com/hakimel/reveal.js#parallax-background">Parallax backgrounds</a></li>
						<li><a href="https://github.com/hakimel/reveal.js#keyboard-bindings">Custom keyboard bindings</a></li>
					</ul>
				</section>

				<section style="text-align: left;">
					<h1>THE END</h1>
					<p>
						- <a href="http://slides.com">Try the online editor</a> <br>
						- <a href="https://github.com/hakimel/reveal.js">Source code &amp; documentation</a>
					</p>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
